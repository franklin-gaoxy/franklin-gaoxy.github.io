
# Hadoop
## 常见端口
50070 HDFS web端口
8088 resourceManager的web端口
50010 50020 8031 8032 8033 ...
2181 zookeeper端口
2888:3888 leader选举
60010 regionServer web端口
16000 16010 16020 hbase

## Hadoop 命令
```shell
# 查看运行中的MapReduce任务
yarn application -list
# 结束掉MapReduce任务
yarn application -kill [application id]
# 查看HDFS文件
hdfs dfs -ls /
# HDFS创建目录
hdfs dfs -mkdir /data
# 删除目录
hdfs dfs -rm -r /data
# 将本地文件上传
hdfs dfs -put /root/test.txt /data/text.txt
```
## Hadoop常见组件
HDFS：NameNode DataNode SecondaryNameNode CheckPointNode 
YARN：resourceManager NodeManager HistoryServer 
HBASE：Hmaster HRegionServer ThriftServer(se fu te)

## Hadoop读取和写入
首先请求Name Node 获取数据实际所在的DataNode的节点列表。
然后对DataNode发起请求，读取数据，然后将数据进行合并。

写入数据时首先对NameNode发起请求，获取一组DataNode的节点列表，然后把要写入的文件切分为多个128M的块。
然后在这组DataNode中选择一个最近的发起写请求，这组DataNode之间互相建立一个“管道”。
当第一个保存完成后，将数据通过管道发送给第二个节点，以此类推，直到最后一个节点写入完成，依次向前返回完成。

> 节点不是随机选择的。首先会随机选择一个节点，接下来会在这个节点相同的机架内随机寻找一个节点作为第二个节点。第三个节点会在不同的机架里随机选择一个节点。

## 机架感知

Hadoop通过配置文件的参数，来指定这个节点处于的机架。
给不同的节点配置上不同的 “机架标识符”，标识符相同的，Hadoop就认为处于同一个机架。
标识符不同的，Hadoop就认为处于不同的机架内。机架感知功能主要是用来HDFS保存数据使用的。

## FSImage和Edit
Hadoop的NameNode使用内存存储元数据信息。为了快速落盘，所以NameNode会以追加写的形式先把所有操作都记录在edits日志中。
一段时间后或者edits日志达到一定数量，那么secondaryNameNode将NameNode节点的多个edits日志和fsimage文件读取过来，截断edits日志，它在自己节点首先恢复fsimage，然后挨个执行edits日志，最后把内存数据合并成一个fsimage，推送到Namenode所在的节点。

> fsimage: 内存数据快照


## 高可用
### 故障转移
故障转移主要依靠ZKFC和zookeeper实现。ZKFC会监控active的namenode，如果下线则将standbyNameNode改为active。
### edits日志同步
日志同步主要依靠journalNode来实现。activeNameNode将日志发送到journalNode。JournalNode会把日志发送给QJM，然后QJM同步日志道standbyName Node的JournalNode上
## 相关问题
### 如果hdfs存储了多个小文件怎么办？
hdfs有一个归档模式，可以把多个文件合并为一个，这样在NameNode中只占用一个文件的内存空间。但是存储的依然是多个独立的文件。
## mapReduce的特点
MapReduce可以做大量数据的分布式计算，但是不能做实时计算和流式计算。
spark 是微批次的计算框架。

Flink是流式计算。

# HBASE
## 表结构
namespace：hbase没有库的概念。namespace就相当于库。默认会有一个default的namespace。
hbase以rowkey为索引，以列族存储数据。
reginon: 以行为单位的切分表。每个reginon分为多个store。
一张表会被截断为多个部分，截断方式主要是依靠列族和rowkey。截断出来的每一部分称作store。
time stamp: 时间戳。hbase分了区分每一条数据操作的先后，使用时间戳来记录。
## hbase读写
### 写入
hbase首先请求zookeeper，zookeeper会返回一个meta表所在的regionServer节点列表。
接下来请求regionServer，获取meta表。然后查询到这个数据要写在那个regionServer。
接下来请求对应的regionServer，regionServer会先保存在memstore中，然后刷写道Hlog.
一段时间后，读取Hlog写入到store file.
storeFile越来越多，会触发合并，将多个storeFile合并为一个。
store file越来越大，region也会越来越大，会触发split，将region切分为多个。
### 读取
先连接zookeeper获取meta表所在的regionServer节点。
访问regionServer获取meta表，然后再查询到数据所在的regionServer节点。
然后请求数据所在节点的regionServer，regionServer先查询缓存，缓存没有再去查询mem store和store file。
## 问题
### region为什么要合并和切分
region是整个表中的一部分数据，按行切割，一个region里面包含了一部分数据（比如100-200行的数据）
store是表中按照列族和region切割的最小单元。只包含了一个列族的100-200行的数据。
当不断往结尾追加数据的时候，region会越来越大，这样某个节点的压力会变大，但是其他节点的压力很小。
所以需要切分region。将它划分为多个部分分布在不同的节点缓解压力。

合并是因为Hadoop不适合存储大量的小文件,因为Hlog是每隔一段时间就写入到store file 如果写操作频繁会产生大量小文件.
### 如果regionServer异常 还可以列出表吗?
可以.HBASE的元数据通过HMaster和zookeeper进行管理,当regionServer异常结束,并不影响列出表,但是不能查看具体的表数据.
# zookeeper
## 特点
原子性，要么成功要么失败，多节点一致性，由leader和follower组成。
## zookeeper选举
> 假如现在有一个五个节点的集群,开始启动.每个节点都有自己的myid文件.
> server1最先启动,节点都是自私的,也就是启动后投票选举他会先投给自己一票
> 但是他发现没有满足集群启动的最小节点数的投票,五节点集群启动需要至少三台,所以他至少需要三票才行.
> 随后server2启动了,server2启动后也投给自己一票,同时因为server1自投选举失败,此时会再次给server2投票,server2同样没有收到足够票数,所以再次选举失败.
> 假如在server1启动成功后,server2和server3一起同时启动,那么server1改投给谁?
> 	每个节点都有自己的myid文件,里面写了一个集群中唯一的数字,server1会投给数字最大的那个节点.
> 	所以,如果Server2和Server3同时启动,Server1会投票给Server3,而Server2也投票给Server3,Server3就满足了最低要求,他就会成为leader节点.
> 随后server3也启动成功了,他也给自己投了一票,随后server1和server2因为选举失败,也投给了server3,此时超过了集群半数,server3选举成功,成为leader.
> 其余节点启动后不需要在进行选举,因为已经存在了leader,所以全部都是follower.

## 相关命令
```shell
zkCli.sh #创建交互式终端
ls /
create /a
delete /a # rmr /a
get /a 

```
# kafka
## kafka高可用实现
分区: 提高并行速度 副本: 提高冗余
kafka的一个topic可以创建多个分区,每个分区还可以创建多个副本,同时维护一个LSR的副本集合.
当leader分区所在节点挂掉以后,可以再LSR中重新选择一个节点作为leader.
## LSR
kafka分区存在多个副本，一个leader和多个follower。
每个follower都从leader处同步数据，但是因为同步的快慢所以每个follower数据并不相同。
lsr是一组follower的集合，同步数据的时候只要这几个follower同步完成，那么就返回写入成功。当leader异常时也从lsr中重新选择leader节点。
# hive
hive支持行存储,也支持列存储.
## 内部表和外部表
内部表指的是在hive内部创建的,元数据和实际数据由hive自身管理.删除时元数据和实际数据全部会被删除.
外部表指的是实际数据在外部的,hive只维护其元数据,比如HBASE的一张表.删除也只删除元数据.
外部表可以转换为内部表.
## 分区表和分桶表
分区表是将一个文件拆分到多个目录存储,在插入数据的时候手动指定写入到那个分区.
分桶表在存储上会拆分为多个文件,插入数据时根据hash值确定写入那个文件.
他们的目的都是用来提高读写速度,因为hive没有索引,执行时需要全表扫描.
